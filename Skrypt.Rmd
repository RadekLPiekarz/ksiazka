---
title: "BostonHousing"
author: "Radek Piekarz"
date: "22 03 2021"
output:
  html_document: default
  pdf_document: default
  word_document: default
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Instalowanie i ladowanie bibliotek

```{r}
if(0){
  install.packages("dplyr")
  install.packages("ggplot2")
  install.packages("caret")
  install.packages("purrr")
  install.packages("corrplot")
  install.packages("tibble")
  install.packages("mlbench")
  install.packages("AmesHousing")}
```

```{r}
library(dplyr)
library(ggplot2)
library(caret)
library(purrr)
library(corrplot)
library(tibble)
library(mlbench)

```


## Ladowanie bazy danych i przeglad zmiennych


```{r}
data(BostonHousing2)
data <- BostonHousing2

data %>% glimpse()
data %>% head()
data %>% summary()


```


## Podzial na probe uczaca i testowa
Dokonujemy podzialu na probe uczaca (70%) i testowa (30%). Analizujemy parametry dwoch zbiorow danych pod katem podobienstwa rozkladu poszczegolnych zmiennych. Sprawdzamy braki danych.

```{r}
set.seed(987654321)
domy_split <- createDataPartition(data$medv, 
                                         p = 0.7, 
                                         list = FALSE) 

domy_train <- data[domy_split,]
domy_test <- data[-domy_split,]

summary(domy_train$medv)
summary(domy_test$medv)

ggplot(domy_train,
       aes(x = medv)) +
  geom_histogram(bins = 200) +
  theme_minimal() +
  geom_histogram(data = domy_test, aes(x = medv), fill = "pink", alpha = 0.4) 
any(is.na(domy_train))
colSums(is.na(domy_train))

```

## Zwykla analiza opisowa (miedzykwarty;lowa)

```{r}
parametry <- read.csv(file = "parametry_lokalu.csv", sep = ";")
parametry
write.csv(parametry, "parametry.xlsx")

```
Otrzymujemy tylko jedna obserwacje z obszaru! Moze wiec szukac po innych kryteriach?

```{r}
tabela <- domy_train %>%  filter(rm >= 4 & rm < 8) %>%filter(age < 30 & age >10) %>%filter(tax < 1000 & tax > 400) %>% summary()

```

Na podstawie tych kryteriow, teoretycznie podobnych do szukanych otrzymujemy cztery obserwacje ze srednia wartosci rowna 26.43. Czy to poprawne podejscie?


## Rodzaje zmiennych

Tu dokonamy przegladu rodzajow zmiennych - ilosciowych i jakosciowych. Zobaczy my poziomy tych zmiennych.

```{r}
domy_zmienne_ilosciowe <- 
  map_lgl(domy_train, is.numeric) %>% 
  which() %>% names()

map_int(domy_train[, domy_zmienne_ilosciowe], 
        function(x) 
          unique(x) %>% 
          length())

domy_zmienne_jakosciowe <- 
  map_lgl(domy_train, is.factor) %>% 
  which() %>% names()

map_int(domy_train[, domy_zmienne_jakosciowe], 
        function(x) 
          unique(x) %>% 
          length())

```

## Korelacja

Dokonamy analizy korelacji ze zmienna celu dla zmiennych ilosciowych. W ten sposob zidentyfikujemy potencjalne wspoliniowosci w modelu. 

```{r}
domy_korelacje_ilosciowe <- cor(domy_train[,domy_zmienne_ilosciowe],
                                use = "pairwise.complete.obs") 

sorted <- domy_korelacje_ilosciowe[,"medv"] %>% 
  sort(decreasing = TRUE) %>%
  names()

sorted


corrplot.mixed(domy_korelacje_ilosciowe[sorted, 
                                        sorted],
               upper = "square",
               lower = "number",
               tl.col="black", # kolor etykietek (nazw zmiennych)
               tl.pos = "lt")  # pozycja etykietek (lt = left and top)


findCorrelation(domy_korelacje_ilosciowe,
                cutoff = 0.9,
                names = TRUE)

ggplot(domy_train,
       aes(x = lstat,
           y = medv)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  theme_bw()
```

Potencjalne skorelowane zmienne ze zmienn celu `medv` to:

* `cmedv`, co jest naturalne. Ta zmienna to skorygowana mediana wartosci. Nie bedziemy jej wykorzystywac w modelu.
* `lstat`, ta zmienna zostawmy przynajmniej w pierwszej wersji modelu.

Dodatkowo, zmienna `tax` i zmienna `rad` sa ze soba skorelowane. Zaakceptujmy je do poczatkowego modelu.

## ANOVA dla zmiennych jakoiowych

Sprawdzmy ich relacje ze zmienna celu

Poniewaz zmienna celu jest ilosciowa, a objasniajace jakosciowe, mozna wykorzystac analize wariancji (ANOVA) aby zbada zwizek tych zmiennych.Z testu **ANOVA** wynika, ze zmienne mozna pozostawic w modelu.

```{r}

summary(aov(domy_train$medv~domy_train$chas))

summary(aov(domy_train$medv~domy_train$town))


ggplot(domy_train,
       aes(x = chas,
           y = medv)) +
  geom_boxplot(fill = "blue") +
  theme_bw()


ggplot(domy_train,
       aes(x = town,
           y = medv)) +
  geom_boxplot(fill = "blue") +
  theme_bw()

```

## Zmienne o zerowej wariancji


```{r}
nearZeroVar(domy_train,
            saveMetrics = TRUE) -> domy_nzv
domy_nzv
write.csv(domy_nzv, "domy_nzv.csv")
```

## Tworzymy zmienne i model

```{r}
domy_zmienne_variable <- names(domy_train)
domy_zmienne_variable
domy_zmienne_variable <- domy_zmienne_variable[-c(1, 3, 4, 6)]

domy_lm1 <- lm(medv ~ .,
               data = domy_train %>% 
                 dplyr::select(domy_zmienne_variable))

domy_lm1.backward <- 
  MASS::stepAIC(domy_lm1, direction = 'backward')



summary(domy_lm1)
summary(domy_lm1.backward)



lista_modeli <- c("domy_lm1", "domy_lm1.backward")

domy_train.pred <- 
  sapply(lista_modeli,
         function(x) predict(get(x)))

domy_train.pred <- as.data.frame(domy_train.pred)
domy_train.pred$obserwowane <- domy_train$medv

domy_test.pred <- 
  sapply(lista_modeli,
         function(x) predict(get(x),
                             newdata = domy_test))


domy_test.pred <- data.frame(domy_test.pred)
domy_test.pred$obserwowane <- domy_test$medv
head(domy_train.pred)

tabela_miar <- matrix(NA, 4, 4)
colnames(tabela_miar) <- 
  c('Train: lm1', 'Train: lm1 backward',
    'Test: lm1',  'Test: lm1 backward')

rownames(tabela_miar) <- c('MAE', 'MAPE', "MSE", 'RMSE')
tabela_miar

tabela_miar_log <- matrix(NA, 4, 4)
colnames(tabela_miar_log) <- 
  c('Train: lm2', 'Train: lm2 backward',
    'Test: lm2',  'Test: lm2 backward')

rownames(tabela_miar_log) <- c('MAE', 'MAPE', "MSE", 'RMSE')

zbiory <- c("train.pred", "test.pred")

for(i in 1:2) {
  for(j in 1:2) {
    miary <- c(
      ModelMetrics::mae( get(paste0("domy_", zbiory[i]))[[3]],
                         get(paste0("domy_", zbiory[i]))[[j]]),
      MLmetrics::MAPE(   get(paste0("domy_", zbiory[i]))[[3]], 
                         get(paste0("domy_", zbiory[i]))[[j]]),
      ModelMetrics::mse( get(paste0("domy_", zbiory[i]))[[3]], 
                         get(paste0("domy_", zbiory[i]))[[j]]),
      ModelMetrics::rmse(get(paste0("domy_", zbiory[i]))[[3]], 
                         get(paste0("domy_", zbiory[i]))[[j]])
    )
    tabela_miar[, (i - 1) * 2 + j] <- miary
    }
}


write.csv(as.data.frame(tabela_miar), "miary.csv")

```

Oba modele - zar?wno oeny jak i backward s podobne. Lekko lepszy jest backward. Ten wyboierzmy jako model ostateczny. 

```{r}
summary(domy_lm1.backward)
parametry 


parametry_lm <- data.frame("tract" = 2052, "crim" = 0.74, "zn" = 0, "chas" = as.factor(0), "nox"= 0.2, "rm" = 6.096, 
                           "dis" = 4.4619, "rad" = 4,  "tax" = 785, "ptratio" = 21, "b"=380.02, "lstat" = 10.26)


predict(domy_lm1.backward, parametry_lm, interval = "confidence", level = 0.95)
```

